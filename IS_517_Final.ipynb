{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T23:16:11.021589Z",
     "start_time": "2025-12-01T23:16:09.967181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================\n",
    "# 1. LOAD AND EXPLORE DATA\n",
    "# ============================================\n",
    "print(\"=\" * 50)\n",
    "print(\"STEP 1: Loading and Exploring Data\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('online_shoppers_intention.csv')\n",
    "\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df['Revenue'].value_counts())\n",
    "print(f\"\\nClass proportion:\")\n",
    "print(df['Revenue'].value_counts(normalize=True))\n",
    "\n",
    "# ============================================\n",
    "# 2. DATA PREPROCESSING\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 2: Data Preprocessing\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('Revenue', axis=1)\n",
    "y = df['Revenue']\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "print(f\"\\nCategorical columns: {list(categorical_cols)}\")\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "    label_encoders[col] = le\n",
    "    print(f\"Encoded {col}: {list(le.classes_)}\")\n",
    "\n",
    "# Convert boolean to integer\n",
    "y = y.astype(int)\n",
    "\n",
    "print(\"\\nPreprocessing complete!\")\n",
    "\n",
    "# ============================================\n",
    "# 3. FEATURE ENGINEERING\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 3: Feature Engineering\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create interaction features as per research question 2\n",
    "X['ProductDuration_PageValue'] = X['ProductRelated_Duration'] * X['PageValues']\n",
    "X['Admin_Bounce_Interaction'] = X['Administrative_Duration'] * X['BounceRates']\n",
    "X['Exit_Bounce_Ratio'] = X['ExitRates'] / (X['BounceRates'] + 0.001)  # Add small value to avoid division by zero\n",
    "\n",
    "print(\"Created interaction features:\")\n",
    "print(\"  - ProductDuration_PageValue\")\n",
    "print(\"  - Admin_Bounce_Interaction\")\n",
    "print(\"  - Exit_Bounce_Ratio\")\n",
    "\n",
    "# ============================================\n",
    "# 4. TRAIN-TEST SPLIT\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 4: Train-Test Split\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "print(f\"Training set class distribution:\\n{y_train.value_counts()}\")\n",
    "\n",
    "# ============================================\n",
    "# 5. HANDLE CLASS IMBALANCE WITH SMOTE\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 5: Handling Class Imbalance with SMOTE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Original training set: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Balanced training set: {pd.Series(y_train_balanced).value_counts().to_dict()}\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_balanced)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ============================================\n",
    "# 6. MODEL TRAINING AND EVALUATION\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 6: Model Training and Evaluation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# ----------------\n",
    "# Logistic Regression\n",
    "# ----------------\n",
    "print(\"\\n--- Logistic Regression ---\")\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train_scaled, y_train_balanced)\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba_lr):.4f}\")\n",
    "\n",
    "results['Logistic Regression'] = {\n",
    "    'predictions': y_pred_lr,\n",
    "    'probabilities': y_pred_proba_lr,\n",
    "    'roc_auc': roc_auc_score(y_test, y_pred_proba_lr)\n",
    "}\n",
    "\n",
    "# ----------------\n",
    "# Random Forest\n",
    "# ----------------\n",
    "print(\"\\n--- Random Forest ---\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba_rf):.4f}\")\n",
    "\n",
    "results['Random Forest'] = {\n",
    "    'predictions': y_pred_rf,\n",
    "    'probabilities': y_pred_proba_rf,\n",
    "    'roc_auc': roc_auc_score(y_test, y_pred_proba_rf)\n",
    "}\n",
    "\n",
    "# ----------------\n",
    "# Support Vector Machine\n",
    "# ----------------\n",
    "print(\"\\n--- Support Vector Machine ---\")\n",
    "svm_model = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "svm_model.fit(X_train_scaled, y_train_balanced)\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "y_pred_proba_svm = svm_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba_svm):.4f}\")\n",
    "\n",
    "results['SVM'] = {\n",
    "    'predictions': y_pred_svm,\n",
    "    'probabilities': y_pred_proba_svm,\n",
    "    'roc_auc': roc_auc_score(y_test, y_pred_proba_svm)\n",
    "}\n",
    "\n",
    "# ============================================\n",
    "# 7. FEATURE IMPORTANCE ANALYSIS\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 7: Feature Importance Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Logistic Regression Coefficients\n",
    "print(\"\\n--- Logistic Regression Feature Coefficients (Top 10) ---\")\n",
    "feature_names = X.columns\n",
    "lr_coef = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': lr_model.coef_[0]\n",
    "}).sort_values('Coefficient', ascending=False)\n",
    "print(lr_coef.head(10))\n",
    "\n",
    "# Random Forest Feature Importance\n",
    "print(\"\\n--- Random Forest Feature Importance (Top 10) ---\")\n",
    "rf_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "print(rf_importance.head(10))\n",
    "\n",
    "# ============================================\n",
    "# 8. VISUALIZATIONS\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 8: Creating Visualizations\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# ROC Curves\n",
    "ax = axes[0, 0]\n",
    "for model_name, result in results.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, result['probabilities'])\n",
    "    ax.plot(fpr, tpr, label=f\"{model_name} (AUC={result['roc_auc']:.3f})\")\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curves Comparison')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Feature Importance (Random Forest)\n",
    "ax = axes[0, 1]\n",
    "top_features = rf_importance.head(10)\n",
    "ax.barh(top_features['Feature'], top_features['Importance'])\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_title('Top 10 Features (Random Forest)')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Logistic Regression Coefficients\n",
    "ax = axes[1, 0]\n",
    "top_coef = lr_coef.head(10)\n",
    "colors = ['green' if x > 0 else 'red' for x in top_coef['Coefficient']]\n",
    "ax.barh(top_coef['Feature'], top_coef['Coefficient'], color=colors)\n",
    "ax.set_xlabel('Coefficient')\n",
    "ax.set_title('Top 10 Feature Coefficients (Logistic Regression)')\n",
    "ax.invert_yaxis()\n",
    "ax.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "\n",
    "# Confusion Matrix (Random Forest - Best Model)\n",
    "ax = axes[1, 1]\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_title('Confusion Matrix (Random Forest)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison_results.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Visualizations saved as 'model_comparison_results.png'\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================\n",
    "# 9. HYPOTHESIS TESTING\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 9: Testing Hypotheses\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Hypothesis 3: Returning visitors convert at higher rates\n",
    "visitor_type_col = 'VisitorType'\n",
    "if visitor_type_col in df.columns:\n",
    "    visitor_conversion = df.groupby(visitor_type_col)['Revenue'].mean()\n",
    "    print(f\"\\nHypothesis 3: Conversion rates by visitor type\")\n",
    "    print(visitor_conversion)\n",
    "\n",
    "# Hypothesis 4: Longer Product-Related Duration positively associated with purchase\n",
    "correlation = df['ProductRelated_Duration'].corr(df['Revenue'])\n",
    "print(f\"\\nHypothesis 4: Correlation between Product Duration and Revenue: {correlation:.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# 10. SUMMARY\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nModel Performance (ROC-AUC):\")\n",
    "for model_name, result in results.items():\n",
    "    print(f\"  {model_name}: {result['roc_auc']:.4f}\")\n",
    "\n",
    "print(\"\\nKey Insights:\")\n",
    "print(\"1. Best performing model:\", max(results.items(), key=lambda x: x[1]['roc_auc'])[0])\n",
    "print(\"2. Most important features identified\")\n",
    "print(\"3. Class imbalance successfully addressed with SMOTE\")\n",
    "print(\"4. Feature engineering completed\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Analysis Complete!\")\n",
    "print(\"=\" * 50)\n"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 11\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msvm\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SVC\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmetrics\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m classification_report, confusion_matrix, roc_auc_score, roc_curve\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mimblearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mover_sampling\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SMOTE\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mwarnings\u001B[39;00m\n\u001B[32m     13\u001B[39m warnings.filterwarnings(\u001B[33m'\u001B[39m\u001B[33mignore\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'imblearn'"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
